{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClusteringAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IeryRg-21c8",
        "outputId": "8e7eef64-6fcd-4b1a-bea5-38a624b32cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip3 install sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "import random\n",
        "import re\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dq87LJcKweL"
      },
      "source": [
        "product_names = []\n",
        "with open('/content/drive/My Drive/Datathon2020/formatted_data/all_products.txt', 'r') as f:\n",
        "  all_products = f.read().split('\\n')[:-1]\n",
        "  for product in all_products:\n",
        "    product_attributes = product.split(',')\n",
        "    product_name_without_space = product_attributes[1].replace('-', ' ')\n",
        "    product_name_without_spaces_or_numbers = ''.join(['' if char.isdigit() else char for char in product_name_without_space])\n",
        "    product_names.append(re.sub(\"([a-z])([A-Z])\",\"\\g<1> \\g<2>\", product_attributes[0]) + ' ' + product_name_without_spaces_or_numbers)\n",
        "random.shuffle(product_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HymuWkJ45CQt"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "training = vectorizer.fit_transform(product_names)\n",
        "\n",
        "k = 9\n",
        "model = KMeans(n_clusters=k, init='k-means++', max_iter=20000, n_init=15, precompute_distances=True)\n",
        "model.fit(training)\n",
        "\n",
        "print(\"Top words per cluster:\")\n",
        "terms = vectorizer.get_feature_names()\n",
        "for i in range(k):\n",
        "    print(\"Cluster %d:\" % i),\n",
        "    for ind in model.cluster_centers_.argsort()[:, ::-1][i, :50]:\n",
        "        print(' %s' % terms[ind]),\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEEhgqXVdJu0"
      },
      "source": [
        "pickle.dump(model, open('/content/drive/My Drive/Datathon2020/machine_learning_models/KMeansClustering/clustering_model.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmdiOW0Tlf0x"
      },
      "source": [
        "pickle.dump(vectorizer, open('/content/drive/My Drive/Datathon2020/machine_learning_models/KMeansClustering/vectorizing_model.sav', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}